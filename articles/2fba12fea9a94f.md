---
title: "es-module-lexerで読み解く依存関係解析"
emoji: "🐷"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ['astro', 'knip', 'deno', 'bun', 'javascript']
published: false
---

## はじめに

聞いたことがない方もいると思います。es-module-lexerはビルドツールやプラグインでよく使われます。私はプライベートでAstroを愛用し、業務ではKnipを組み込んでいたりします。それらは、当然es-module-lexerを使用しているのです。

小さなライブラリes-module-lexerが、大規模ソースコードを瞬時に解析する様子に衝撃を受けたことはよく覚えています。本稿では実装を通じて仕組みを紐解き、AstroとKnipで実践されている例、さらにDenoとBunが採る多様な依存解析戦略までを知った備忘録です。

## 依存解析の 2 つのアプローチ: Parser と Lexer 

全部読む Full Parser 型と場所だけ見るLexer 型という二つの流派があります。理解するためにBabel/Acornとes-module-lexerで対比してみましょう。

Babel、Acornは、本を頭から読み込み、章や節を整理し、どの場面で誰が何をしているかまで細かく把握して目次を作る全文読破型です。すべてを理解するぶん時間も手間もかかりますが、その結果できあがる目次は物語の流れや背景まで丸ごとわかる立派なものになります。そのため、70万行を超えるAngular 1のバンドルを約 100ms秒で走査します。

一方、es-module-lexerは、とにかくページをめくるスピード勝負の索引作成型です。

めくりながら”import”や”export”といった単語を見つけた瞬間、そこへ付箋を貼り “何ページのどこにあるか” だけをメモして次のページへ進みます。文章の内容や登場人物の関係は一切読まないのです。大事なのは”場所”だけ。だから膨大なページでもあっという間に仕事が終わります。

> For an example of the performance, Angular 1 (720 KiB) is fully parsed in 5 ms, in comparison to the fastest JS parser, Acorn which takes over 100 ms.

70万行を超えるAngular 1のバンドルを約 5ms秒で走査するほどです。

#### 内部 — 状態遷移と実装ポイント

UTF-16 文字列を先頭から順に走査し、コメント・文字列・テンプレートリテラルに入れば終端までジャンプ、通常コードに戻った瞬間だけ `i m p o r t` や `e x p o r t` との照合を行う――これを状態遷移テーブルで機械的にこなします。結果として得られるのは

```js
[
  { s: 1024, e: 1047, t: "static" },
  { s: 2096, e: 2122, t: "dynamic" },
  …
]
```

という“開始オフセット s・終了オフセット e・静的／動的フラグ t”だけの配列。木を育てないぶんメモリ確保は最小で、Angular 1 の 70 万行バンドルでも約 5 ms で走査を終えるのも納得です。

先述した Astro や Knip が es-module-lexer を採用するのは、“座標だけ測量する” という哲学がビルド体験を劇的に短縮するからにほかなりません。どのように組み込まれているのか、Astro と Knip の実装を見ていきましょう。

## Knip で未使用依存を CI で撲滅

Knip は CI パイプラインで未使用のファイルや依存パッケージを自動検出し、本番ブランチへの混入を防ぐための静的解析ツールである。プロジェクト直下にあるすべてのソースを対象に import / export を列挙し、逆方向に依存グラフをたどることで「どこからも参照されないノード」を削除候補として浮かび上がらせる。

あなたの町には、給水塔から伸びる太い本管と、家ごとに分かれていく細い枝管があります。ふだんは給水塔から家へ向かって水が流れますが、今回やりたいのはその逆です。まず「この家の蛇口に来ている水は本当に給水塔につながっているのか」を確かめるつもりで、蛇口から本管へ向かって管を一本ずつ手で触りながらたどります。

GitHub Actions で pnpm knip --production を実行すると、彩色されなかった依存が存在する場合ジョブが失敗する。開発者は PR の段階で警告を受け取るため、不要ライブラリが本番ブランチに混入しない。結果として Vite の optimizeDeps キャッシュが汚れず、Astro の再ビルド時間も短縮される。実際の案件では三つの未使用依存と二つの不要ファイルを指摘したジョブが五〜六秒で完了し、レビュー前に問題を解消できた。

Knip による定期的なクリーンアップは、開発中に増えがちな枝管を早期に閉栓し、長期的なパフォーマンス低下を防ぐ仕組みとして機能している。

## Astro が実現する “最小 JS”

Astro はその座標を使い、Vite に「どのファイルを事前バンドルし、どれを遅延読み込みするか」を即断させる。これがアイランドアーキテクチャで“必要最小限の JS”を実現する要です。

### 郵便仕分けで見る Astro × Vite

#### 仕分けタグを貼る機械 ―― es-module-lexer

ソースファイルがベルトコンベヤーに載るたび、es-module-lexer は封筒の表面だけを瞬時にスキャンして宛先 ZIP コード、つまり `import` 先の文字列だけを抜き取り、仕分けタグを貼る。封筒の中身を開けて文面を読むことは一切なく、位置と種類をメモするだけなので処理がきわめて軽い。

#### タグを読んで振り分ける係員 ―― Vite

次の工程では Vite が貼られたタグを読み取り、同じ市内あての封筒はまとめて即日トラックに載せ、海外便は倉庫に置いておき航空便が飛ぶタイミングで送り出す。`import React from "react"` のような静的インポートは “市内便” としてプリバンドルに回り、`import("./heavy.js")` のような動的インポートは “海外便” として後で必要になった瞬間にロードされる仕組みだ。

#### 配送の行き先を最適化する効果

こうして「すぐ届ける荷物」と「あとで届ける荷物」が自動で分かれるため、開発サーバー起動時には必要最小限の JavaScript だけがまとめてブラウザへ送られ、初回表示が高速になる。一方で動的インポートはユーザーが本当に訪れたときにだけネットワークに乗るので、ページ全体の負荷を増やさない。郵便局の素早い仕分けが街じゅうの配達をスムーズにするのと同じ理屈で、es-module-lexer と Vite の連係が Astro のアイランドアーキテクチャを支えている。

## Deno Graph と Bun Lexer — 対照的な戦略

DenoとBunに見る依存解析の多様化

ここではDenoとBunが「依存グラフをどうやって瞬時に組むか」を、空港手荷物検査と宅急便の仕分けラインにたとえて対比する。

6.1 Deno — 空港でのX線＋開封検査

DenoはRust製ライブラリdeno_graphを保安検査場に置く。流れは次のとおり。

乗客（＝ソースファイル）がレーンに乗ると、まずX線装置（トークン化）が全荷物を輪切りにし、形を記録する。

形を見ただけでは不審物か判定できないため、検査官がスーツケースを開けて中身まで確認し、精密リスト（AST）を作る。

リストをもとに「誰がどこへ向かうか」をマップ化し、結果をキャッシュ倉庫に保管する。

ここでX線＋開封検査に相当するのがAST生成であり、TypeScriptであっても型情報まで取り込んで「不審物ゼロ保証」を得る。一度開封してしまえば、次に同じ乗客が来てもパスポートナンバー（ファイルハッシュ）だけでスルーできるので再検査はゼロコストだ。

6.2 Bun — 宅急便のバーコード仕分けベルト

BunはC++ とZigのハイブリッドで、バーコードスキャナ（レキサ）を何台も並べた仕分けベルトを走らせる。

荷物（＝ファイル）がベルトに乗ると、バーコード（importキーワード）だけを秒速で読む。

読み取った行き先ラベルを即座に分配器へ送信し、箱を開けずにルートを振り分ける。

必要に応じてプラグインがonBeforeParseフック経由でベルトの上を流れる箱を直接タッチし、中身をコピーせずに検査結果をメモする（ゼロコピー）。

バーコード読み取りがトークンレベル解析に相当し、開封はしないので極限まで速い。しかも仕分け員（スレッド）を何人も並べることで大量の荷物を同時処理できる。

6.3何が起こるのか

観点

Deno (deno_graph)

Bun (独自Lexer)

イメージ

X線＋開封検査

バーコード仕分け

手法

ASTを丸ごと構築

トークンだけ抽出

長所

型情報まで信頼性◎、2回目以降は完全キャッシュ

初回から瞬時、並列化が効きやすい

短所

初回コストがやや高い

JSXなど新構文対応は実装を追随させる負担

この違いがもたらすのは「どこでコストを払うか」の選択だ。

Denoは初回に重い検査を一気に終え、「型まで正しい保証」を得て以後はキャッシュで逃げ切る。大型トランスパイルや型チェックをCIで省けるメリットが大きい。

Bunは検査を最小化し、速さを最優先する。たとえばbun testやbun runがNode.jsより桁違いに速いのは、開封を後回しにしてバーコードだけで走らせる設計のおかげだ。

どちらの方式でも「ビルド → 実行」の境目が曖昧になり、TypeScriptを保存して即実行というワンステップ開発が現実になる点は共通している。

## 限界と今後の拡張（JSX, Type アノテーション対応など）

Angular 1という70万行の歴史的大規模バンドルを実験台にした複数の計測レポートでは、es‑module‑lexerのWebAssembly版が約五ミリ秒、Rust製deno_graphが八ミリ秒前後、BunのC++ レキサが三〜四ミリ秒という数字が報告されている。これらはすべて「AST生成を省くか、あるいは極度に効率化する」アプローチの賜物であり、従来百ミリ秒単位だったフルパーサとの差を決定的に広げている。

結果として起こるのは「スタートアップ遅延の消失」である。対話的なREPL、スクリプト的CLI、テストランナー、サーバーレス関数など、従来はウォームアップ数百ミリ秒を許容していた場面で待ち時間の存在自体が意識されなくなる。Bunではbun testがNode.js + Jest比で20倍以上速いという声もあり、依存解析コストが支配的だったユースケースで顕著に差が出ている。

ただし限界も存在する。es‑module‑lexerは素のJSXやTSXを直接読めないため、AstroやViteは事前にesbuildを呼んでimportの形へ正規化する。Rust派生のrs-module-lexerやBun内蔵パーサはJSXをそのまま受け取れるが、言語仕様が拡張されるたびにC++／Rust側の実装を追随させねばならない。高速化と保守負荷は常にトレードオフである。

それでも三〜四ミリ秒というレベルまで来ると、ビルドパイプラインとランタイムが不可分になっていく。bunx create-next-appのように「実行しながら依存を解析し、キャッシュに書き込んで次のrunに備える」ツール設計が一般化する。Node.js界隈でもESBuildやnode --loaderフックを通じて類似の統合が進み、開発体験は "type once, run everywhere immediately" へ収束しつつある。

